{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVibP+CI72nT3xsMFEulhv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoNav/springboard/blob/main/Train_test_Split_and_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train test split\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "w4xZGsV77Qvp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydvA8oUz6oK1"
      },
      "outputs": [],
      "source": [
        "# The first step is to split your data into two pieces, a training set and a testing set.\n",
        "# Typically, about 75% of the data goes to your training set and about 25% of your data goes to the test set.\n",
        "# The second step of the process is to train the model on the training set.\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_california_housing()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "df.head()"
      ],
      "metadata": {
        "id": "s49cjXd9-0zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features matrix\n",
        "x = df.loc[:,['HouseAge','AveRooms','AveBedrms']].values\n",
        "\n",
        "# target vector\n",
        "y = df.loc[:, 'target'].values"
      ],
      "metadata": {
        "id": "y45SXiCrBRcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=3)"
      ],
      "metadata": {
        "id": "uGLyLr8ZEtW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a linear regression instance\n",
        "reg = LinearRegression(fit_intercept=True)\n",
        "\n",
        "#  Train the model on the training set\n",
        "reg.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "DsqB24OYFAQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model on the testing set and evaluate performance\n",
        "score = reg.score(x_test,y_test)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "UGpxOrEkFckZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PrfClfncPUs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Be sure to clear all outputs from above before proceeding\n",
        "# Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "xxc_Q9vEPm6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A1 us virginica flower and a 0 is versicolor flower\n",
        "df = pd.read_csv('/content/sample_data/modifiedIris2Classes.csv')\n",
        "df.shape\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Ypui9z1-RVPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data into training and testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(df[['petal length (cm)']], df['target'],random_state=0)"
      ],
      "metadata": {
        "id": "9iAvtTxuS5TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standardize the data:**\n",
        "A really important part of this process is to standardize your data. Logistic regression is affected by scale, so you need to scale your features onto unit scale for optimal performance. Unit scale means having a mean of 0 and a variance of 1 for your features. You can utilize scikit-learn's standard scaler to accomplish this."
      ],
      "metadata": {
        "id": "p3lGFAzuYdKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on taining set only\n",
        "scaler.fit(x_train)\n",
        "\n",
        "# Apply transform to both the training set and the test set\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "rfblhfLLWus5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make instance of model\n",
        "clf = LogisticRegression()\n",
        "\n",
        "# Training the model on the data, storing the information learned from the data\n",
        "# Model is learning the relationship between x(features sepal width, sepal hight ect) and y (labels-which species of iris)\n",
        "clf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "sIrUQDCOb0UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the labels of new data (new flowers)"
      ],
      "metadata": {
        "id": "Hkw0f-Rydo0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one observation  petal length after standardization\n",
        "x_test[0].reshape(1,-1)"
      ],
      "metadata": {
        "id": "Rt9mHsLUdDov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('prediction', clf.predict(x_test[0].reshape(1,-1))[0])\n",
        "print('probability', clf.predict_proba(x_test[0].reshape(1,-1)))\n",
        "# What this code is showing is a prediction for one flower sample. The prediction was zero.\n",
        "# The probability of a zero, according to the model was 0.52, the probability of one was 0.47."
      ],
      "metadata": {
        "id": "2SGreCFeeBFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy is defined as: correct predictions/ total number of data points\n",
        "score = clf.score(x_test,y_test)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "ZJrrr1-Jegx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression for multiclass Classification\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "XlTJLgi3gOLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Be sure to clear all outputs from above before proceeding\n",
        "# Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "UYsjwMqNglBi"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('/content/sample_data/modifiedDigits4Classes.csv')\n",
        "df.head()\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD1jEEv_nauD",
        "outputId": "20d39087-5b49-462e-d899-13fff9f69821"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(720, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Each Digit"
      ],
      "metadata": {
        "id": "Riu2WGzWqpEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_colnames = df.columns[:-1]\n",
        "pixel_colnames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnpLR77vn6vb",
        "outputId": "2c7069ec-06eb-424a-ce17-08d88c8f9951"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
              "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
              "       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36',\n",
              "       '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n",
              "       '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60',\n",
              "       '61', '62', '63'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all columns except the label column for first image\n",
        "image_values = df.loc[0, pixel_colnames].values\n",
        "image_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcqz6CxxoT0p",
        "outputId": "0b940a27-7d88-4740-fb04-c26324aa4aec"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  5, 13,  9,  1,  0,  0,  0,  0, 13, 15, 10, 15,  5,  0,  0,\n",
              "        3, 15,  2,  0, 11,  8,  0,  0,  4, 12,  0,  0,  8,  8,  0,  0,  5,\n",
              "        8,  0,  0,  9,  8,  0,  0,  4, 11,  0,  1, 12,  7,  0,  0,  2, 14,\n",
              "        5, 10, 12,  0,  0,  0,  0,  6, 13, 10,  0,  0,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,2))\n",
        "for index in range(0,4):\n",
        "  plt.subplot(1,5,1 + index)\n",
        "  image_values = df.loc[index, pixel_colnames].values\n",
        "  image_label = df.loc[index,'label']\n",
        "  plt.imshow(image_values.reshape(8,8), cmap ='gray')\n",
        "  plt.title('Label:' + str(image_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "GEWGRNOPop7t",
        "outputId": "1b73b21a-5f96-410f-e6b7-182f78ca261f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into Training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(df[pixel_colnames], df['label'],random_state=0)"
      ],
      "metadata": {
        "id": "yUbSdBACq6Yi"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on training set only\n",
        "scaler.fit(x_train)\n",
        "\n",
        "# Apply transform to both the training set and the test set\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "DSYA94YJrOOr"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression\n",
        "\n",
        "# multi-class is specifying one versus rest\n",
        "clf = LogisticRegression(solver='liblinear', multi_class='ovr', random_state=0)\n",
        "\n",
        "clf.fit(x_train, y_train)\n",
        "print('Training accuracy:', clf.score(x_train, y_train))\n",
        "print('Test accuracy:', clf.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-BhbpXcrRxB",
        "outputId": "479a0f2b-49fb-4a38-d257-178f437b256b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 1.0\n",
            "Test accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf.intercept_)\n",
        "print(clf.coef_.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah9wVr0jvtZf",
        "outputId": "9338be5e-854b-4963-c523-956d236c4e19"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.712674   -3.54379096 -3.18367757 -2.623974  ]\n",
            "(4, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "# the second class is the highest score it will be the prediction for this data\n",
        "clf.predict_proba(x_test[0:1])\n",
        "# clf.predict(x_test[0:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkI1cVc2v6l4",
        "outputId": "3af111c4-2894-4899-dd26-5c9d5af1b51d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    }
  ]
}